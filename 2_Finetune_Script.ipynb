{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBTE-SW8r_ad",
        "outputId": "8be5b522-0178-4f15-c345-ff20075371fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UtnfbZjsmSI",
        "outputId": "65b9f47d-376b-415c-cab9-477a455a22e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Installation of Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "XP-n3Z-7B1SJ",
        "outputId": "9cc8cbc6-bb75-4e2b-95b4-9b2d92cfa764"
      },
      "outputs": [],
      "source": [
        "!pip install lightning==2.4.0\n",
        "# !pip install nemo_toolkit==2.0.0\n",
        "!pip install transformers datasets sentencepiece librosa jiwer soundfile\n",
        "# 1. Fix the NumPy version (Crucial for Colab right now)\n",
        "!pip install \"numpy<2.0\"\n",
        "\n",
        "# 2. Install missing NeMo dependency\n",
        "!pip install hydra-core\n",
        "\n",
        "# 3. Re-install NeMo with ASR dependencies just to be safe\n",
        "!pip install \"nemo_toolkit[asr]==2.0.0\"\n",
        "\n",
        "# Note: You MUST restart the runtime after running this cell for the NumPy change to take effect.\n",
        "# Go to \"Runtime\" -> \"Restart Session\" (or Ctrl+M .)\n",
        "# Force uninstall conflicting version and install standard version\n",
        "!pip uninstall -y numpy\n",
        "!pip install \"numpy<2.0\"\n",
        "!pip install datasets==3.0.2\n",
        "!pip install pyarrow==14.0.1\n",
        "!pip install nemo_toolkit==2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61lWXA_EBAAM"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"Path to your Tokenizer Directory\"\n",
        "BASE_DIR = \"Path to your base directory or Folder\"\n",
        "MANIFEST_DIR = f\"{BASE_DIR}/manifests\"\n",
        "AUDIO_DIR = f\"{BASE_DIR}/audio/decoded_audio\"\n",
        "TOKENIZER_DIR = f\"{BASE_DIR}/tokenizer\"\n",
        "CHECKPOINT_DIR = f\"{BASE_DIR}/checkpoints\"\n",
        "LOG_DIR = f\"{BASE_DIR}/logs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tbt9zZ3CzyY"
      },
      "source": [
        "## BPE tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAeil1vuDJzg"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import json\n",
        "import sentencepiece as spm\n",
        "import nemo.collections.asr as nemo_asr\n",
        "from nemo.collections.common.tokenizers import SentencePieceTokenizer\n",
        "\n",
        "print(\"Starting BPE Tokenizer training...\")\n",
        "\n",
        "# DATA_DIR = \"/content/drive/MyDrive/ASR_richard/tokenizer\"\n",
        "text_corpus_path = os.path.join(DATA_DIR, 'text_corpus.txt')\n",
        "\n",
        "# --- Step 1: Extract text corpus ---\n",
        "print(\"Extracting text from manifest...\")\n",
        "with open(os.path.join(MANIFEST_DIR, 'train_manifest.json'), 'r') as f_manifest, \\\n",
        "     open(text_corpus_path, 'w') as f_text:\n",
        "    for line in f_manifest:\n",
        "        try:\n",
        "            entry = json.loads(line)\n",
        "            f_text.write(entry['text'] + '\\n')\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Skipping bad line: {line}\")\n",
        "\n",
        "print(\"âœ… Text corpus extracted.\")\n",
        "\n",
        "# --- Step 2: Train SentencePiece tokenizer directly ---\n",
        "print(\"Training SentencePiece model...\")\n",
        "tokenizer_prefix = os.path.join(DATA_DIR, 'tokenizer_1024_bpe')\n",
        "\n",
        "spm.SentencePieceTrainer.Train(\n",
        "    input=text_corpus_path,\n",
        "    model_prefix=tokenizer_prefix,\n",
        "    vocab_size=1024,\n",
        "    model_type='bpe',\n",
        "    character_coverage=1.0,\n",
        "    bos_id=1,\n",
        "    eos_id=2,\n",
        "    unk_id=0,\n",
        "    pad_id=-1,\n",
        "    user_defined_symbols=[]\n",
        ")\n",
        "\n",
        "print(f\"âœ… SentencePiece model trained and saved to:\")\n",
        "print(f\"{tokenizer_prefix}.model\")\n",
        "print(f\"{tokenizer_prefix}.vocab\")\n",
        "\n",
        "# --- Step 3: Load into NeMo Tokenizer for verification ---\n",
        "tokenizer = SentencePieceTokenizer(model_path=f\"{tokenizer_prefix}.model\")\n",
        "print(\"âœ… NeMo tokenizer loaded successfully!\")\n",
        "print(\"Sample tokens:\", tokenizer.text_to_tokens(\"HELLO WORLD\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Zz24bMjtvJ"
      },
      "source": [
        "## imports and all........."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8P1siMaxlTpo",
        "outputId": "b329efb1-53e7-43c8-f1a5-b620918d7c01"
      },
      "outputs": [],
      "source": [
        "import huggingface_hub\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "# import lightning.pytorch as pl\n",
        "# from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
        "# from lightning.pytorch.loggers import TensorBoardLogger\n",
        "# from lightning.pytorch import Trainer\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import sentencepiece as spm\n",
        "print(\"huggingface_hub:\", huggingface_hub.__version__)\n",
        "from omegaconf import OmegaConf, open_dict\n",
        "\n",
        "\n",
        "from nemo.collections.common.tokenizers import SentencePieceTokenizer\n",
        "from nemo.collections.asr.models import EncDecCTCModel\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning import Trainer\n",
        "\n",
        "print(\"âœ… NeMo imports working fine!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx-xgjrtFHf6"
      },
      "source": [
        "## Model loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "crmqoCPykhho"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/drive/MyDrive/ASR_richard\"\n",
        "MANIFEST_DIR = f\"{BASE_DIR}/manifests\"\n",
        "AUDIO_DIR = f\"{BASE_DIR}/audio/decoded_audio\"\n",
        "TOKENIZER_DIR = f\"{BASE_DIR}/tokenizer_nemo\"\n",
        "CHECKPOINT_DIR = f\"{BASE_DIR}/checkpoints\"\n",
        "LOG_DIR = f\"{BASE_DIR}/logs\"\n",
        "\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "# --- 1. Use Your Defined Paths ---\n",
        "\n",
        "\n",
        "TRAIN_MANIFEST = f\"{MANIFEST_DIR}/train_manifest.json\"\n",
        "DEV_CLEAN_MANIFEST = f\"{MANIFEST_DIR}/dev_clean_manifest.json\"\n",
        "DEV_OTHER_MANIFEST = f\"{MANIFEST_DIR}/dev_other_manifest.json\"\n",
        "\n",
        "# You can Increase Batch size as per your GPU V-RAM Capacity\n",
        "BATCH_SIZE = 40\n",
        "NUM_WORKERS = 25\n",
        "SAMPLE_RATE = 16000\n",
        "\n",
        "# --- 2. Load the Pre-trained Conformer-CTC Model ---\n",
        "print(f\"\\nLoading pre-trained model: \")\n",
        "\n",
        "asr_model = EncDecCTCModel.from_pretrained(\"nvidia/stt_en_fastconformer_ctc_large\")\n",
        "print(\"âœ… Model loaded.\")\n",
        "\n",
        "\n",
        "\n",
        "asr_model.change_vocabulary(\n",
        "    new_tokenizer_dir=TOKENIZER_DIR,\n",
        "    new_tokenizer_type=\"bpe\"\n",
        ")\n",
        "\n",
        "print(\"âœ… Tokenizer updated and Decoder resized.\")\n",
        "\n",
        "cfg = asr_model.cfg\n",
        "\n",
        "with open_dict(cfg):\n",
        "    # Stronger SpecAugment (robustness) to improve WER on dev_other\n",
        "    cfg.spec_augment.freq_masks = 3\n",
        "    cfg.spec_augment.freq_width = 30\n",
        "    cfg.spec_augment.time_masks = 10\n",
        "    cfg.spec_augment.time_width = 0.08\n",
        "\n",
        "    # Lower LR for fine-tuning\n",
        "    cfg.optim.sched.name = \"NoamHoldAnnealing\"\n",
        "    cfg.optim.sched.warmup_steps = 0\n",
        "    cfg.optim.sched.hold_steps = 1000000  \n",
        "    cfg.optim.sched.decay_rate = 1.0\n",
        "    cfg.optim.sched.min_lr = 5e-5\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- 4. Setup Data Loaders (ONLY DO THIS NOW) ---\n",
        "# We define the configs here and load them AFTER the vocab change.\n",
        "\n",
        "train_cfg = {\n",
        "    \"manifest_filepath\": TRAIN_MANIFEST,\n",
        "    \"sample_rate\": SAMPLE_RATE,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"shuffle\": True,\n",
        "    \"num_workers\": NUM_WORKERS,\n",
        "    \"pin_memory\": True,\n",
        "    \"trim_silence\": True,\n",
        "    # \"max_duration\": 20.0,\n",
        "    \"min_duration\": 0.1,\n",
        "    \"is_tarred\": False,\n",
        "    \"persistent_workers\": True\n",
        "}\n",
        "\n",
        "val_other_cfg = {\n",
        "    \"manifest_filepath\": DEV_OTHER_MANIFEST,\n",
        "    \"sample_rate\": SAMPLE_RATE,\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"shuffle\": False,\n",
        "    \"num_workers\": NUM_WORKERS,\n",
        "    \"name\": \"dev_other\",\n",
        "}\n",
        "\n",
        "print(\"Setting up Training Data...\")\n",
        "asr_model.setup_training_data(train_cfg)\n",
        "\n",
        "print(\"Setting up Validation Data...\")\n",
        "asr_model.setup_validation_data(val_other_cfg)\n",
        "\n",
        "print(\"âœ… Model successfully configured!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dhx3tmMUcl1V"
      },
      "outputs": [],
      "source": [
        "# Checkpoint Callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=CHECKPOINT_DIR,\n",
        "    filename=\"fastconformer-{epoch:02d}-{val_wer:.3f}\",\n",
        "    monitor=\"val_wer\",  \n",
        "    mode=\"min\",\n",
        "    save_top_k=2,\n",
        "    save_last=True,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "# Logger\n",
        "logger = TensorBoardLogger(save_dir=LOG_DIR, name=\"FastConformer_Finetune\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouBw9zeScxur",
        "outputId": "be732855-f023-4d3d-caef-88b57ef4b94f"
      },
      "outputs": [],
      "source": [
        "# --- 5. Set Up Trainer (Using your settings) ---\n",
        "trainer = Trainer(\n",
        "    accelerator=\"gpu\",\n",
        "    devices=1,\n",
        "    # precision=16,               \n",
        "    precision=\"bf16-mixed\",                \n",
        "    max_epochs=20,               \n",
        "    logger=logger,\n",
        " \n",
        "    callbacks=[checkpoint_callback],\n",
        "    val_check_interval=1.0,\n",
        "    accumulate_grad_batches=4,   # Gradient accumulation\n",
        "    log_every_n_steps=100,\n",
        "    default_root_dir=CHECKPOINT_DIR,\n",
        ")\n",
        "\n",
        "# Attach trainer (only need to do this once)\n",
        "asr_model.set_trainer(trainer)\n",
        "print(\"âœ… Trainer initialized. Without Early Stopping\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-yWa2b_iI-8",
        "outputId": "43a7a3f5-6933-4728-97ee-88786d51ca0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Decoding strategy changed to: greedy_batch\n"
          ]
        }
      ],
      "source": [
        "from omegaconf import open_dict\n",
        "\n",
        "# 1. Modify the decoding strategy in the model config\n",
        "with open_dict(asr_model.cfg.decoding):\n",
        "    asr_model.cfg.decoding.strategy = \"greedy_batch\"\n",
        "\n",
        "print(f\"âœ… Decoding strategy changed to: {asr_model.cfg.decoding.strategy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QarNur6KuaZR",
        "outputId": "3054825e-9fbb-4310-8877-9f4f3dbfa411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Applied STRONG patch: 'weights_only=False' is now forced globally.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import omegaconf\n",
        "\n",
        "\n",
        "#    and forces weights_only=False\n",
        "def force_unsafe_load(f, map_location=None, pickle_module=None, **pickle_load_args):\n",
        "    # Force the safe-load flag to False\n",
        "    pickle_load_args['weights_only'] = False\n",
        "\n",
        "    # Check if we've already backed up the original (to avoid recursion loops)\n",
        "    if hasattr(torch, '_original_load'):\n",
        "        return torch._original_load(f, map_location, pickle_module, **pickle_load_args)\n",
        "    else:\n",
        "        # Fallback if _original_load isn't set yet \n",
        "        return torch.jit.load(f) \n",
        "\n",
        "# 2. Apply the patch\n",
        "if not hasattr(torch, '_original_load'):\n",
        "    torch._original_load = torch.load  # Save the real function\n",
        "    torch.load = force_unsafe_load     # Replace with forced wrapper\n",
        "\n",
        "print(\"âœ… Applied STRONG patch: 'weights_only=False' is now forced globally.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "h91yItnKtL0o"
      },
      "outputs": [],
      "source": [
        "from nemo.collections.asr.models import EncDecCTCModelBPE\n",
        "\n",
        "manual_ckpt = \"/content/drive/MyDrive/ASR_richard/checkpoints/fastconformer-epoch=19-val_wer=0.061.ckpt\"\n",
        "\n",
        "print(\"ðŸ”„ Loading model weights ONLY (no decoder reset)\")\n",
        "asr_model = EncDecCTCModelBPE.load_from_checkpoint(manual_ckpt)\n",
        "\n",
        "# âŒ DO NOT call change_vocabulary here\n",
        "# âŒ DO NOT touch tokenizer again\n",
        "\n",
        "# Apply SpecAugment + LR changes\n",
        "cfg = asr_model.cfg\n",
        "with open_dict(cfg):\n",
        "    cfg.spec_augment.freq_masks = 3\n",
        "    cfg.spec_augment.freq_width = 30\n",
        "    cfg.spec_augment.time_masks = 10\n",
        "    cfg.spec_augment.time_width = 0.08\n",
        "\n",
        "    cfg.optim.lr = 5e-5\n",
        "\n",
        "    # constant LR scheduler\n",
        "    cfg.optim.sched.name = \"NoamHoldAnnealing\"\n",
        "    cfg.optim.sched.warmup_steps = 0\n",
        "    cfg.optim.sched.hold_steps = 1_000_000\n",
        "    cfg.optim.sched.decay_rate = 1.0\n",
        "    cfg.optim.sched.min_lr = 5e-5\n",
        "\n",
        "# Reattach data\n",
        "asr_model.setup_training_data(train_cfg)\n",
        "asr_model.setup_validation_data(val_other_cfg)\n",
        "\n",
        "asr_model.set_trainer(trainer)\n",
        "trainer.fit(asr_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export / Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xc3NOyzhJ8sI"
      },
      "outputs": [],
      "source": [
        "best_ckpt_path = checkpoint_callback.best_model_path\n",
        "print(\"Best checkpoint:\", best_ckpt_path)\n",
        "\n",
        "# Load PL checkpoint correctly\n",
        "best_model = EncDecCTCModel.load_from_checkpoint(best_ckpt_path)\n",
        "\n",
        "# Export to .nemo format\n",
        "best_model.save_to(f\"{CHECKPOINT_DIR}/best_model_04.nemo\")\n",
        "\n",
        "print(\"âœ… Successfully exported best model to .nemo\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlr38DKx71rd",
        "outputId": "f4ed5b7e-3353-4724-bf1b-04c7ca1788d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model fine-tuned and saved successfully!\n"
          ]
        }
      ],
      "source": [
        "asr_model.save_to(f\"{CHECKPOINT_DIR}/fastconformer_finetuned_dev_other_03.nemo\")\n",
        "print(\"âœ… Model fine-tuned and saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5bUSMU9EBfn"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ac79f57bd8a4f26bd24b955e325f5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be5b3763592f4e7198a851ff8dc200c2",
            "max": 463155200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ae82882e4e6e41e1ab0969e2e34dda47",
            "value": 463155200
          }
        },
        "52e160f028d341c29db9e37658ddbc16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "758fba1747d04a3daeb62c9c482827a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7758dd2e87214bf8b67970a211e5ff79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99268db1ce7c4f288192b6ac014f2c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd25b29416c49deaf149b4319f81739",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_758fba1747d04a3daeb62c9c482827a5",
            "value": "stt_en_fastconformer_ctc_large.nemo:â€‡100%"
          }
        },
        "ae82882e4e6e41e1ab0969e2e34dda47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc4b71fbf9184fada7b26ed1039dd37b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be5b3763592f4e7198a851ff8dc200c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a74187ec9c4e75ad0f937e327cb1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7758dd2e87214bf8b67970a211e5ff79",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_52e160f028d341c29db9e37658ddbc16",
            "value": "â€‡463M/463Mâ€‡[00:04&lt;00:00,â€‡201MB/s]"
          }
        },
        "dcd25b29416c49deaf149b4319f81739": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea719b8971f47f297f27f3017b978a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99268db1ce7c4f288192b6ac014f2c2c",
              "IPY_MODEL_2ac79f57bd8a4f26bd24b955e325f5db",
              "IPY_MODEL_c7a74187ec9c4e75ad0f937e327cb1a9"
            ],
            "layout": "IPY_MODEL_bc4b71fbf9184fada7b26ed1039dd37b"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
