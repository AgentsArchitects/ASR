{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15923,
     "status": "ok",
     "timestamp": 1765359293469,
     "user": {
      "displayName": "Binod Kumar",
      "userId": "10613330231784289661"
     },
     "user_tz": -330
    },
    "id": "5LmRWgHnmfli",
    "outputId": "f376c096-6240-4650-e1f2-241df32c5fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# # Add force_remount=True to fix the error\n",
    "# drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# # 1. Delete the existing (conflicting) directory\n",
    "!rm -rf /content/drive\n",
    "\n",
    "# 2. Try mounting again\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 88145,
     "status": "ok",
     "timestamp": 1766149253448,
     "user": {
      "displayName": "Binod Kumar",
      "userId": "10613330231784289661"
     },
     "user_tz": -330
    },
    "id": "jbLgXyB9iHCt",
    "outputId": "2398a796-fcee-44ac-edb7-58c11cbb1d07"
   },
   "outputs": [],
   "source": [
    "!pip install lightning==2.4.0\n",
    "# !pip install nemo_toolkit==2.0.0\n",
    "!pip install transformers datasets sentencepiece librosa jiwer soundfile\n",
    "# 1. Fix the NumPy version (Crucial for Colab right now)\n",
    "!pip install \"numpy<2.0\"\n",
    "\n",
    "# 2. Install missing NeMo dependency\n",
    "!pip install hydra-core\n",
    "\n",
    "# 3. Re-install NeMo with ASR dependencies just to be safe\n",
    "!pip install \"nemo_toolkit[asr]==2.0.0\"\n",
    "\n",
    "# Note: You MUST restart the runtime after running this cell for the NumPy change to take effect.\n",
    "# Go to \"Runtime\" -> \"Restart Session\" (or Ctrl+M .)\n",
    "!pip uninstall -y numpy\n",
    "!pip install \"numpy<2.0\"\n",
    "!pip install datasets==3.0.2\n",
    "!pip install pyarrow==14.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 18246,
     "status": "ok",
     "timestamp": 1766149585811,
     "user": {
      "displayName": "Binod Kumar",
      "userId": "10613330231784289661"
     },
     "user_tz": -330
    },
    "id": "51BR4khCiRVt",
    "outputId": "5eecbd51-7328-4c5b-cdd9-d46890d13ae3"
   },
   "outputs": [],
   "source": [
    "import huggingface_hub\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import sentencepiece as spm\n",
    "print(\"huggingface_hub:\", huggingface_hub.__version__)\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "\n",
    "from nemo.collections.common.tokenizers import SentencePieceTokenizer\n",
    "from nemo.collections.asr.models import EncDecCTCModel\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "print(\"âœ… NeMo imports working fine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Path correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1185,
     "status": "ok",
     "timestamp": 1766149590307,
     "user": {
      "displayName": "Binod Kumar",
      "userId": "10613330231784289661"
     },
     "user_tz": -330
    },
    "id": "7UaQCiVDaHfq"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = \"Path to your base directory\"\n",
    "MANIFEST_DIR = f\"{BASE_DIR}/manifests\"\n",
    "AUDIO_DIR = f\"{BASE_DIR}/audio/decoded_audio\"\n",
    "TOKENIZER_DIR = f\"{BASE_DIR}/tokenizer_nemo\"\n",
    "CHECKPOINT_DIR = f\"{BASE_DIR}/checkpoints\"\n",
    "LOG_DIR = f\"{BASE_DIR}/logs\"\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "TRAIN_MANIFEST = f\"{MANIFEST_DIR}/train_manifest.json\"\n",
    "DEV_CLEAN_MANIFEST = f\"{MANIFEST_DIR}/dev_clean_manifest.json\"\n",
    "DEV_OTHER_MANIFEST = f\"{MANIFEST_DIR}/dev_other_manifest.json\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnbYLQx_k_f1"
   },
   "source": [
    "## Load best checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1766149601999,
     "user": {
      "displayName": "Binod Kumar",
      "userId": "10613330231784289661"
     },
     "user_tz": -330
    },
    "id": "iDGl61SnoMyF",
    "outputId": "9a4cc3d8-93f0-4125-e944-1d5b08b4b5e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Applied STRONG patch: 'weights_only=False' is now forced globally.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if not hasattr(torch, '_original_load'):\n",
    "    def force_unsafe_load(f, map_location=None, pickle_module=None, **pickle_load_args):\n",
    "        # Force weights_only=False to allow DictConfig objects\n",
    "        pickle_load_args['weights_only'] = False\n",
    "\n",
    "        if hasattr(torch, '_original_load'):\n",
    "            return torch._original_load(f, map_location, pickle_module, **pickle_load_args)\n",
    "        return torch.jit.load(f) # Fallback\n",
    "\n",
    "    torch._original_load = torch.load\n",
    "    torch.load = force_unsafe_load\n",
    "    print(\"âœ… Applied STRONG patch: 'weights_only=False' is now forced globally.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 25561,
     "status": "ok",
     "timestamp": 1766149823599,
     "user": {
      "displayName": "Binod Kumar",
      "userId": "10613330231784289661"
     },
     "user_tz": -330
    },
    "id": "3qQFtirzk-xs",
    "outputId": "81f5938d-c63b-411c-f7c1-1f8947cd42a5"
   },
   "outputs": [],
   "source": [
    "# UPDATE THIS PATH to your actual best checkpoint file\n",
    "CHECKPOINT_PATH = \"PATH to your actual best checkpoint file\"\n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"Loading model from: {CHECKPOINT_PATH}\")\n",
    "    # Load model from checkpoint\n",
    "    asr_model = EncDecCTCModel.load_from_checkpoint(CHECKPOINT_PATH)\n",
    "\n",
    "\n",
    "    # Set to evaluation mode \n",
    "    asr_model.eval()\n",
    "    asr_model.to(\"cuda\") \n",
    "    print(\"âœ… Model loaded and moved to GPU.\")\n",
    "else:\n",
    "    print(f\"âŒ Error: Checkpoint not found at {CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "nXVOL1BG8vMN"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import soundfile as sf\n",
    "from jiwer import wer\n",
    "import re, string\n",
    "\n",
    "print(\"\\nðŸ” Running MANUAL WER evaluation (jiwer 4.x compatible)...\")\n",
    "\n",
    "manifest_path = \"Manifest Path\"\n",
    "\n",
    "\n",
    "from omegaconf import open_dict\n",
    "\n",
    "with open_dict(asr_model.cfg.decoding):\n",
    "    asr_model.cfg.decoding.strategy = \"beam\"\n",
    "    asr_model.cfg.decoding.beam.beam_size = 8\n",
    "    asr_model.cfg.decoding.beam.alpha = 1.0\n",
    "    asr_model.cfg.decoding.beam.beta = 0.0\n",
    "\n",
    "print(\"âœ… Beam decoding enabled for evaluation\")\n",
    "\n",
    "\n",
    "preds = []\n",
    "refs = []\n",
    "\n",
    "\n",
    "\n",
    "def detokenize_sentencepiece(text):\n",
    "    text = text.replace(\"<s>\", \"\").replace(\"</s>\", \"\")\n",
    "    text = text.replace(\"â–\", \" \")\n",
    "    return \" \".join(text.split()).strip()\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "with open(manifest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        entry = json.loads(line)\n",
    "        audio_path = entry[\"audio_filepath\"]\n",
    "        ref_text = entry[\"text\"].strip()\n",
    "\n",
    "        audio, sr = sf.read(audio_path)\n",
    "        if len(audio.shape) > 1:\n",
    "            audio = audio.mean(axis=1)\n",
    "        audio = audio.astype(\"float32\")\n",
    "\n",
    "        raw_pred = asr_model.transcribe([audio])[0]\n",
    "        clean_pred = detokenize_sentencepiece(raw_pred)\n",
    "\n",
    "        refs.append(normalize_text(ref_text))\n",
    "        preds.append(normalize_text(clean_pred))\n",
    "\n",
    "        if i < 6:\n",
    "            print(\"\\nREF :\", ref_text)\n",
    "            print(\"PRED:\", clean_pred)\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nâš¡ Computing final normalized WER...\")\n",
    "final_wer = wer(refs, preds)\n",
    "\n",
    "print(f\"\\nðŸ† FINAL NORMALIZED WER = {final_wer * 100:.2f}%\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6zLM7iDU4M-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO3R9wLjtuXAJUKwGZIfpjR",
   "gpuType": "L4",
   "machine_shape": "hm",
   "mount_file_id": "1BdhpQwcadayn7nniBY7OfHNpUFIDIvMz",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
